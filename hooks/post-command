#!/bin/bash
set -uo pipefail

DIR="$(cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd)"

# shellcheck source=lib/plugin.bash
. "$DIR/../lib/plugin.bash"
# shellcheck source=lib/logs.bash
. "$DIR/../lib/logs.bash"

MODEL=$(plugin_read_config MODEL "anthropic.claude-3-7-sonnet-20250219-v1:0")
INFERENCE_PROFILE=$(plugin_read_config INFERENCE_PROFILE "us.anthropic.claude-3-7-sonnet-20250219-v1:0")
TRIGGER=$(plugin_read_config TRIGGER "on-failure")
ANALYSIS_LEVEL=$(plugin_read_config ANALYSIS_LEVEL "step")
MAX_LOG_LINES=$(plugin_read_config MAX_LOG_LINES "1000")
CUSTOM_PROMPT=$(plugin_read_config CUSTOM_PROMPT "")
TIMEOUT=$(plugin_read_config TIMEOUT "60")
ANNOTATE=$(plugin_read_config ANNOTATE "true")
AGENT_FILE=$(plugin_read_config AGENT_FILE "false")
COMPARE_BUILDS=$(plugin_read_config COMPARE_BUILDS "false")
COMPARISON_RANGE=$(plugin_read_config COMPARISON_RANGE "5")

# Source validation functions
# shellcheck disable=SC1091
. "$DIR/../lib/validation.bash"

# Validate required tools
validate_tools || exit 1

# Validate configuration
validate_configuration "${MODEL}" "${INFERENCE_PROFILE}" "${TRIGGER}" "${ANALYSIS_LEVEL}" "${COMPARE_BUILDS}" "$(plugin_read_config BUILDKITE_API_TOKEN "")" || exit 1

echo "--- :robot_face: Bedrock Summarize Plugin (Post-Command)"

echo "Model: ${MODEL}"
echo "Inference Profile: ${INFERENCE_PROFILE}"
echo "Trigger: ${TRIGGER}"
echo "Analysis Level: ${ANALYSIS_LEVEL}"
echo "Max log lines: ${MAX_LOG_LINES}"
[ "${COMPARE_BUILDS}" = "true" ] && echo "Build Comparison: ENABLED (last ${COMPARISON_RANGE} builds)" || echo "Build Comparison: disabled"

# Get the command exit status from Buildkite
COMMAND_EXIT_STATUS="${BUILDKITE_COMMAND_EXIT_STATUS:-0}"

echo "Command completed with exit status: ${COMMAND_EXIT_STATUS}"

# Add a progress indicator for better UX
echo "--- :gear: Preparing AI analysis"

# Check if we should trigger AI analysis
if should_trigger_analysis "${TRIGGER}" "${COMMAND_EXIT_STATUS}"; then
  echo "--- :mag: Triggering AI analysis"

  # Perform analysis (disable exit on error temporarily)
  set +e
  ANALYSIS=$(analyze_build_failure "${MODEL}" "${INFERENCE_PROFILE}" "${MAX_LOG_LINES}" "${CUSTOM_PROMPT}" "${TIMEOUT}" "${AGENT_FILE}" "${ANALYSIS_LEVEL}" "${COMPARE_BUILDS}" "${COMPARISON_RANGE}")
  ANALYSIS_EXIT_CODE=$?
  set -e

  if [ ${ANALYSIS_EXIT_CODE} -eq 0 ]; then
    echo "--- :white_check_mark: Analysis completed"

    # Create annotation if enabled
    if [ "${ANNOTATE}" = "true" ]; then
      annotation_style="info"
      annotation_title="AI Build Analysis"

      # Change style based on build status
      if [ "${COMMAND_EXIT_STATUS}" -ne 0 ]; then
        annotation_style="error"
        if [ "${ANALYSIS_LEVEL}" = "build" ]; then
          annotation_title="AI Build Failure Analysis"
        else
          annotation_title="AI Step Failure Analysis"
        fi
      else
        if [ "${ANALYSIS_LEVEL}" = "build" ]; then
          annotation_title="AI Build Analysis"
        else
          annotation_title="AI Step Analysis"
        fi
      fi

      # Create a temp file for the annotation
      annotation_file="/tmp/ai_success_${BUILDKITE_BUILD_ID}.md"

      # Write the formatted annotation to the file
      cat > "${annotation_file}" << ANNOTATION
## ${annotation_title}

### 📊 Summary

**Pipeline:** ${BUILDKITE_PIPELINE_SLUG:-Unknown} | **Build:** [#${BUILDKITE_BUILD_NUMBER:-Unknown}](${BUILDKITE_BUILD_URL:-#}) | **Status:** $([ "${BUILDKITE_COMMAND_EXIT_STATUS:-0}" -ne 0 ] && echo "❌ Failed (${BUILDKITE_COMMAND_EXIT_STATUS})" || echo "✅ Passed")

---

### 📋 $([ "${ANALYSIS_LEVEL}" = "build" ] && echo "Build" || echo "Step") Information

$([ "${ANALYSIS_LEVEL}" = "step" ] && echo "**Step:** ${BUILDKITE_LABEL:-Unknown}  ")
$([ "${ANALYSIS_LEVEL}" = "step" ] && echo "**Command:** \`${BUILDKITE_COMMAND:-Unknown}\`  ")
**Branch:** ${BUILDKITE_BRANCH:-Unknown}
**Commit:** \`${BUILDKITE_COMMIT:-Unknown}\`
$([ "${COMPARE_BUILDS}" = "true" ] && echo "**Historical Comparison:** Analyzing last ${COMPARISON_RANGE} builds  ")

---

### 🤖 AI Analysis

${ANALYSIS}

---

<sub>Generated by ${MODEL} via Bedrock at $(date)</sub>
ANNOTATION

      # Use the file for annotation
      formatted_analysis="${annotation_file}"

      create_annotation "${annotation_title}" "${formatted_analysis}" "${annotation_style}"
    fi

  # Check if analysis was successful
  if [ -n "${ANALYSIS}" ] && [[ ! "${ANALYSIS}" =~ ^Error: ]]; then
    if [ "${ANNOTATE}" = "true" ]; then
      echo "--- :brain: AI Analysis Complete (See Annotation)"
    else
      echo "--- :brain: AI Analysis Complete"
    fi
  else
    echo "--- :warning: AI analysis failed"
    if [ "${ANNOTATE}" = "true" ]; then
      # Create a temp file for the error annotation
      error_file="/tmp/ai_error_${BUILDKITE_BUILD_ID}.md"

      # Write the formatted error annotation to the file
      cat > "${error_file}" << ERROR
## ⚠️ AI Analysis Failed

**Error:** ${ANALYSIS}

---

### 🔍 Troubleshooting Information

**Current Configuration:**
- Model: ${MODEL}
- Inference Profile: ${INFERENCE_PROFILE}
- Trigger: ${TRIGGER}
- Analysis Level: ${ANALYSIS_LEVEL}
$([ "${COMPARE_BUILDS}" = "true" ] && echo "- Historical Comparison: Last ${COMPARISON_RANGE} builds")

**Common Causes:**
- AWS CLI missing or misconfigured
- Network connectivity issues
- API rate limits exceeded
- Service temporarily unavailable

**Resolution Steps:**
1. Verify that AWS CLI is installed and can connect to Amazon Web Services
2. Ensure the Buildkite agent has internet access
4. Visit [health.aws.amazon.com](https://health.aws.amazon.com/health/status) to check service status

---

<sub>Generated at $(date)</sub>
ERROR
      error_annotation="${error_file}"
      create_annotation "AI Analysis Failed" "${error_annotation}" "warning"
    fi
  fi
  fi
else
  echo "--- :zzz: Skipping AI analysis (trigger: ${TRIGGER}, exit status: ${COMMAND_EXIT_STATUS})"
fi

true
exit 0
